<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Portfolios on Jiajie Li</title>
    <link>https://jiajie.media/portfolio/</link>
    <description>Recent content in Portfolios on Jiajie Li</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 08 Mar 2021 15:07:22 +0800</lastBuildDate><atom:link href="https://jiajie.media/portfolio/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Identifying human interactions in built environment: deep learning analytics on camera data for urban vibrancy evaluation</title>
      <link>https://jiajie.media/portfolio/vibrancy/</link>
      <pubDate>Mon, 08 Mar 2021 15:07:22 +0800</pubDate>
      
      <guid>https://jiajie.media/portfolio/vibrancy/</guid>
      <description>Identifying human interactions in built environment: deep learning analytics on camera data for urban vibrancy evaluation   Abstract Spatial revitalization has been widely regarded as the main goal for urban design. The increasing availability of multi-source data in recent years enables researchers to create better metrics to evaluate vibrancy. Despite the consensus that the count of people flow works as a significant indicator, it is incomplete for loosing information about activities in which people are involved.</description>
    </item>
    
    <item>
      <title>Parasite-Host Network for Video Crowd Counting</title>
      <link>https://jiajie.media/portfolio/phnet/</link>
      <pubDate>Mon, 08 Mar 2021 15:07:22 +0800</pubDate>
      
      <guid>https://jiajie.media/portfolio/phnet/</guid>
      <description>Parasite-Host Network for Video Crowd Counting   Demo Video, Github
Abstract Crowd counting plays an increasingly important role in public security. Recently, many crowd counting methods for a single image have been proposed but few studies have focused on using temporal information from image sequences of videos to improve prediction performance. In the existing methods using videos for crowd estimation, temporal features and spatial features are modeled jointly for the prediction, which makes the model less efficient in extracting spatiotemporal features and difficult to improve the performance of predictions.</description>
    </item>
    
    <item>
      <title>Supporting Therapeutic Storytelling and Therapist’s Neutrality in Sandtray Therapy Through a Digital Twin</title>
      <link>https://jiajie.media/portfolio/therapy/</link>
      <pubDate>Mon, 08 Mar 2021 15:07:22 +0800</pubDate>
      
      <guid>https://jiajie.media/portfolio/therapy/</guid>
      <description>Supporting Therapeutic Storytelling and Therapist’s Neutrality in Sandtray Therapy Through a Digital Twin   Abstract Sandtray therapy is a form of expressive therapy. Taking the form of a digital twin system, we present a novel tool to support sandtray therapy, designed to inspire the client’s self-expression and use quantitative data to supervise therapists to become more neutral. As figurines are placed by clients, the screen displays a living virtual world synchronously using computer vision.</description>
    </item>
    
    <item>
      <title>Equity WITHOUT Zoning</title>
      <link>https://jiajie.media/portfolio/ewz/</link>
      <pubDate>Mon, 08 Mar 2021 14:40:53 +0800</pubDate>
      
      <guid>https://jiajie.media/portfolio/ewz/</guid>
      <description>Equity WITHOUT Zoning   Link to the online version: http://ewz.media.mit.edu/
Link to the docker repository: https://hub.docker.com/r/jajamoa/css2020
Featured Video   Workshop Record    </description>
    </item>
    
  </channel>
</rss>
